{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "iris = load_iris()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=iris.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "y=iris.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((150, 4), (150,))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape,y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn = KNeighborsClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "           metric_params=None, n_jobs=None, n_neighbors=5, p=2,\n",
       "           weights='uniform')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn.fit(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 2, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 1, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[50,  0,  0],\n",
       "       [ 0, 47,  3],\n",
       "       [ 0,  2, 48]], dtype=int64)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y,knn.predict(X))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# representing text as numerical data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "simple_train = ['call you tonight', 'Call me a cab', 'please call me... PLEASE!']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "vect = CountVectorizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "        ngram_range=(1, 1), preprocessor=None, stop_words=None,\n",
       "        strip_accents=None, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "        tokenizer=None, vocabulary=None)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vect.fit(simple_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['cab', 'call', 'me', 'please', 'tonight', 'you']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vect.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'call': 1, 'you': 5, 'tonight': 4, 'me': 2, 'cab': 0, 'please': 3}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vect.vocabulary_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<3x6 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 9 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "simple_train_dtm = vect.transform(simple_train)\n",
    "simple_train_dtm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 1, 0, 0, 1, 1],\n",
       "       [1, 1, 1, 0, 0, 0],\n",
       "       [0, 1, 1, 2, 0, 0]], dtype=int64)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "simple_train_dtm.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['call you tonight', 'Call me a cab', 'please call me... PLEASE!']"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "simple_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cab</th>\n",
       "      <th>call</th>\n",
       "      <th>me</th>\n",
       "      <th>please</th>\n",
       "      <th>tonight</th>\n",
       "      <th>you</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   cab  call  me  please  tonight  you\n",
       "0    0     1   0       0        1    1\n",
       "1    1     1   1       0        0    0\n",
       "2    0     1   1       2        0    0"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "import pandas as pd\n",
    "pd.DataFrame(simple_train_dtm.toarray(), columns=vect.get_feature_names())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sandY\\AppData\\Local\\conda\\conda\\envs\\tensorflow\\lib\\site-packages\\ipykernel_launcher.py:1: FutureWarning: read_table is deprecated, use read_csv instead, passing sep='\\t'.\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "sms = pd.read_table('https://raw.githubusercontent.com/justmarkham/pycon-2016-tutorial/master/data/sms.tsv', header=None, names=['label', 'message'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    Go until jurong point, crazy.. Available only ...\n",
       "1                        Ok lar... Joking wif u oni...\n",
       "2    Free entry in 2 a wkly comp to win FA Cup fina...\n",
       "3    U dun say so early hor... U c already then say...\n",
       "4    Nah I don't think he goes to usf, he lives aro...\n",
       "5    FreeMsg Hey there darling it's been 3 week's n...\n",
       "6    Even my brother is not like to speak with me. ...\n",
       "7    As per your request 'Melle Melle (Oru Minnamin...\n",
       "8    WINNER!! As a valued network customer you have...\n",
       "9    Had your mobile 11 months or more? U R entitle...\n",
       "Name: message, dtype: object"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sms.message.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ham     4825\n",
       "spam     747\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sms.label.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "sms['label_num'] = sms.label.map({'ham':0, 'spam':1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=sms.message"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "y=sms.label_num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4179,)\n",
      "(1393,)\n",
      "(4179,)\n",
      "(1393,)\n"
     ]
    }
   ],
   "source": [
    "# split X and y into training and testing sets\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=1)\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "vect = CountVectorizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "vect.fit(X_train)\n",
    "X_train_dtm = vect.transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<4179x7456 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 55209 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_dtm = vect.fit_transform(X_train)\n",
    "\n",
    "\n",
    "# examine the document-term matrix\n",
    "X_train_dtm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<1393x3508 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 16824 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# transform testing data (using fitted vocabulary) into a document-term matrix\n",
    "X_test_dtm = vect.transform(X_test)\n",
    "X_test_dtm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "nb = MultinomialNB()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True)"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nb.fit(X_train_dtm,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1202,    6],\n",
       "       [  11,  174]], dtype=int64)"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_test,nb.predict(X_test_dtm))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9877961234745154"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nb.score(X_test_dtm,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9900796491856095"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "# calculate predicted probabilities for X_test_dtm (poorly calibrated)\n",
    "y_pred_prob = nb.predict_proba(X_test_dtm)[:, 1]\n",
    "y_pred_prob\n",
    "\n",
    "\n",
    "# calculate AUC\n",
    "metrics.roc_auc_score(y_test, y_pred_prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9900796491856095"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics.roc_auc_score(y_test, y_pred_prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x45436e2ac8>]"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "fpr,tpr,threshold=metrics.roc_curve(y_test, y_pred_prob)\n",
    "plt.plot(fpr,tpr,color=\"red\")\n",
    "plt.plot([0,1],[0,1],color=\"BLUE\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sandY\\AppData\\Local\\conda\\conda\\envs\\tensorflow\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9798994974874372"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import and instantiate a logistic regression model\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "logreg = LogisticRegression()\n",
    "\n",
    "\n",
    "# train the model using X_train_dtm\n",
    "logreg.fit(X_train_dtm, y_train)\n",
    "\n",
    "\n",
    "# make class predictions for X_test_dtm\n",
    "y_pred_class = logreg.predict(X_test_dtm)\n",
    "\n",
    "\n",
    "# calculate predicted probabilities for X_test_dtm (well calibrated)\n",
    "y_pred_prob = logreg.predict_proba(X_test_dtm)[:, 1]\n",
    "y_pred_prob\n",
    "\n",
    "\n",
    "# calculate accuracy\n",
    "metrics.accuracy_score(y_test, y_pred_class)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.,  0.,  0., ...,  1.,  1.,  1.],\n",
       "       [ 5., 23.,  2., ...,  0.,  0.,  0.]])"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# rows represent classes, columns represent tokens\n",
    "nb.feature_count_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., ..., 1., 1., 1.])"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# number of times each token appears across all HAM messages\n",
    "ham_token_count = nb.feature_count_[0, :]\n",
    "ham_token_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 5., 23.,  2., ...,  0.,  0.,  0.])"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# number of times each token appears across all SPAM messages\n",
    "spam_token_count = nb.feature_count_[1, :]\n",
    "spam_token_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7204"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# store the vocabulary of X_train\n",
    "X_train_tokens = vect.get_feature_names()\n",
    "len(X_train_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['00', '000', '008704050406', '0121', '01223585236', '01223585334', '0125698789', '02', '0207', '02072069400', '02073162414', '02085076972', '021', '03', '04', '0430', '05', '050703', '0578', '06', '07', '07008009200', '07090201529', '07090298926', '07123456789', '07732584351', '07734396839', '07742676969', '0776xxxxxxx', '07781482378', '07786200117', '078', '07801543489', '07808', '07808247860', '07808726822', '07815296484', '07821230901', '07880867867', '0789xxxxxxx', '07946746291', '0796xxxxxx', '07973788240', '07xxxxxxxxx', '08', '0800', '08000407165', '08000776320', '08000839402', '08000930705']\n"
     ]
    }
   ],
   "source": [
    "# examine the first 50 tokens\n",
    "print(X_train_tokens[0:50])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ham</th>\n",
       "      <th>spam</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>token</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>zoom</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zouk</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zyada</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>èn</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>〨ud</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       ham  spam\n",
       "token           \n",
       "zoom   1.0   0.0\n",
       "zouk   0.0   1.0\n",
       "zyada  1.0   0.0\n",
       "èn     1.0   0.0\n",
       "〨ud    1.0   0.0"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create a DataFrame of tokens with their separate ham and spam counts\n",
    "tokens = pd.DataFrame({'token':X_train_tokens, 'ham':ham_token_count, 'spam':spam_token_count}).set_index('token')\n",
    "tokens.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ham</th>\n",
       "      <th>spam</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>token</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>iphone</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>450ppw</th>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>join</th>\n",
       "      <td>9.0</td>\n",
       "      <td>13.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dontcha</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>brings</th>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         ham  spam\n",
       "token             \n",
       "iphone   1.0   0.0\n",
       "450ppw   0.0   2.0\n",
       "join     9.0  13.0\n",
       "dontcha  0.0   1.0\n",
       "brings   4.0   1.0"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# examine 5 random DataFrame rows\n",
    "tokens.sample(5, random_state=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3617.  562.]\n",
      "[[3602   15]\n",
      " [  12  550]]\n",
      "3617\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Naive Bayes counts the number of observations in each class\n",
    "print(nb.class_count_) ## are th classes present in original daata set\n",
    "print(confusion_matrix(y_train,nb.predict(X_train_dtm)))\n",
    "print(3603+14)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.865518\n",
       "1    0.134482\n",
       "Name: label_num, dtype: float64"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ham</th>\n",
       "      <th>spam</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>token</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>iphone</th>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>450ppw</th>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>join</th>\n",
       "      <td>10.0</td>\n",
       "      <td>14.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dontcha</th>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>brings</th>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          ham  spam\n",
       "token              \n",
       "iphone    2.0   1.0\n",
       "450ppw    1.0   3.0\n",
       "join     10.0  14.0\n",
       "dontcha   1.0   2.0\n",
       "brings    5.0   2.0"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# add 1 to ham and spam counts to avoid dividing by 0\n",
    "tokens['ham'] = tokens.ham + 1\n",
    "tokens['spam'] = tokens.spam + 1\n",
    "tokens.sample(5, random_state=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ham</th>\n",
       "      <th>spam</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>token</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>iphone</th>\n",
       "      <td>0.000553</td>\n",
       "      <td>0.001779</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>450ppw</th>\n",
       "      <td>0.000276</td>\n",
       "      <td>0.005338</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>join</th>\n",
       "      <td>0.002765</td>\n",
       "      <td>0.024911</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dontcha</th>\n",
       "      <td>0.000276</td>\n",
       "      <td>0.003559</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>brings</th>\n",
       "      <td>0.001382</td>\n",
       "      <td>0.003559</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              ham      spam\n",
       "token                      \n",
       "iphone   0.000553  0.001779\n",
       "450ppw   0.000276  0.005338\n",
       "join     0.002765  0.024911\n",
       "dontcha  0.000276  0.003559\n",
       "brings   0.001382  0.003559"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# convert the ham and spam counts into frequencies\n",
    "tokens['ham'] = tokens.ham / nb.class_count_[0]\n",
    "tokens['spam'] = tokens.spam / nb.class_count_[1]\n",
    "tokens.sample(5, random_state=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ham</th>\n",
       "      <th>spam</th>\n",
       "      <th>spam_ratio</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>token</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>iphone</th>\n",
       "      <td>0.000553</td>\n",
       "      <td>0.001779</td>\n",
       "      <td>3.217972</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>450ppw</th>\n",
       "      <td>0.000276</td>\n",
       "      <td>0.005338</td>\n",
       "      <td>19.307829</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>join</th>\n",
       "      <td>0.002765</td>\n",
       "      <td>0.024911</td>\n",
       "      <td>9.010320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dontcha</th>\n",
       "      <td>0.000276</td>\n",
       "      <td>0.003559</td>\n",
       "      <td>12.871886</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>brings</th>\n",
       "      <td>0.001382</td>\n",
       "      <td>0.003559</td>\n",
       "      <td>2.574377</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              ham      spam  spam_ratio\n",
       "token                                  \n",
       "iphone   0.000553  0.001779    3.217972\n",
       "450ppw   0.000276  0.005338   19.307829\n",
       "join     0.002765  0.024911    9.010320\n",
       "dontcha  0.000276  0.003559   12.871886\n",
       "brings   0.001382  0.003559    2.574377"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# calculate the ratio of spam-to-ham for each token\n",
    "tokens['spam_ratio'] = tokens.spam / tokens.ham\n",
    "tokens.sample(5, random_state=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ham</th>\n",
       "      <th>spam</th>\n",
       "      <th>spam_ratio</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>token</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>claim</th>\n",
       "      <td>0.000276</td>\n",
       "      <td>0.158363</td>\n",
       "      <td>572.798932</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>prize</th>\n",
       "      <td>0.000276</td>\n",
       "      <td>0.135231</td>\n",
       "      <td>489.131673</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>150p</th>\n",
       "      <td>0.000276</td>\n",
       "      <td>0.087189</td>\n",
       "      <td>315.361210</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tone</th>\n",
       "      <td>0.000276</td>\n",
       "      <td>0.085409</td>\n",
       "      <td>308.925267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>guaranteed</th>\n",
       "      <td>0.000276</td>\n",
       "      <td>0.076512</td>\n",
       "      <td>276.745552</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.000276</td>\n",
       "      <td>0.069395</td>\n",
       "      <td>251.001779</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cs</th>\n",
       "      <td>0.000276</td>\n",
       "      <td>0.065836</td>\n",
       "      <td>238.129893</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>www</th>\n",
       "      <td>0.000553</td>\n",
       "      <td>0.129893</td>\n",
       "      <td>234.911922</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1000</th>\n",
       "      <td>0.000276</td>\n",
       "      <td>0.056940</td>\n",
       "      <td>205.950178</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>awarded</th>\n",
       "      <td>0.000276</td>\n",
       "      <td>0.053381</td>\n",
       "      <td>193.078292</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>150ppm</th>\n",
       "      <td>0.000276</td>\n",
       "      <td>0.051601</td>\n",
       "      <td>186.642349</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>uk</th>\n",
       "      <td>0.000553</td>\n",
       "      <td>0.099644</td>\n",
       "      <td>180.206406</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>500</th>\n",
       "      <td>0.000276</td>\n",
       "      <td>0.048043</td>\n",
       "      <td>173.770463</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ringtone</th>\n",
       "      <td>0.000276</td>\n",
       "      <td>0.044484</td>\n",
       "      <td>160.898577</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mob</th>\n",
       "      <td>0.000276</td>\n",
       "      <td>0.042705</td>\n",
       "      <td>154.462633</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>000</th>\n",
       "      <td>0.000276</td>\n",
       "      <td>0.042705</td>\n",
       "      <td>154.462633</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>collection</th>\n",
       "      <td>0.000276</td>\n",
       "      <td>0.039146</td>\n",
       "      <td>141.590747</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000</th>\n",
       "      <td>0.000276</td>\n",
       "      <td>0.037367</td>\n",
       "      <td>135.154804</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>valid</th>\n",
       "      <td>0.000276</td>\n",
       "      <td>0.037367</td>\n",
       "      <td>135.154804</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10p</th>\n",
       "      <td>0.000276</td>\n",
       "      <td>0.037367</td>\n",
       "      <td>135.154804</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>800</th>\n",
       "      <td>0.000276</td>\n",
       "      <td>0.037367</td>\n",
       "      <td>135.154804</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8007</th>\n",
       "      <td>0.000276</td>\n",
       "      <td>0.035587</td>\n",
       "      <td>128.718861</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.000553</td>\n",
       "      <td>0.067616</td>\n",
       "      <td>122.282918</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>weekly</th>\n",
       "      <td>0.000276</td>\n",
       "      <td>0.033808</td>\n",
       "      <td>122.282918</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tones</th>\n",
       "      <td>0.000276</td>\n",
       "      <td>0.032028</td>\n",
       "      <td>115.846975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>land</th>\n",
       "      <td>0.000276</td>\n",
       "      <td>0.032028</td>\n",
       "      <td>115.846975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>http</th>\n",
       "      <td>0.000276</td>\n",
       "      <td>0.032028</td>\n",
       "      <td>115.846975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5000</th>\n",
       "      <td>0.000276</td>\n",
       "      <td>0.030249</td>\n",
       "      <td>109.411032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>national</th>\n",
       "      <td>0.000276</td>\n",
       "      <td>0.030249</td>\n",
       "      <td>109.411032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sae</th>\n",
       "      <td>0.000276</td>\n",
       "      <td>0.030249</td>\n",
       "      <td>109.411032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>didn</th>\n",
       "      <td>0.011335</td>\n",
       "      <td>0.001779</td>\n",
       "      <td>0.156974</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>coming</th>\n",
       "      <td>0.011612</td>\n",
       "      <td>0.001779</td>\n",
       "      <td>0.153237</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>wat</th>\n",
       "      <td>0.023500</td>\n",
       "      <td>0.003559</td>\n",
       "      <td>0.151434</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fine</th>\n",
       "      <td>0.011888</td>\n",
       "      <td>0.001779</td>\n",
       "      <td>0.149673</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gonna</th>\n",
       "      <td>0.012165</td>\n",
       "      <td>0.001779</td>\n",
       "      <td>0.146271</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>late</th>\n",
       "      <td>0.012165</td>\n",
       "      <td>0.001779</td>\n",
       "      <td>0.146271</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>oh</th>\n",
       "      <td>0.024882</td>\n",
       "      <td>0.003559</td>\n",
       "      <td>0.143021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ya</th>\n",
       "      <td>0.012441</td>\n",
       "      <td>0.001779</td>\n",
       "      <td>0.143021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>went</th>\n",
       "      <td>0.012718</td>\n",
       "      <td>0.001779</td>\n",
       "      <td>0.139912</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ll</th>\n",
       "      <td>0.052530</td>\n",
       "      <td>0.007117</td>\n",
       "      <td>0.135494</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>feel</th>\n",
       "      <td>0.013824</td>\n",
       "      <td>0.001779</td>\n",
       "      <td>0.128719</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>told</th>\n",
       "      <td>0.013824</td>\n",
       "      <td>0.001779</td>\n",
       "      <td>0.128719</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gud</th>\n",
       "      <td>0.014100</td>\n",
       "      <td>0.001779</td>\n",
       "      <td>0.126195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cos</th>\n",
       "      <td>0.014929</td>\n",
       "      <td>0.001779</td>\n",
       "      <td>0.119184</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>amp</th>\n",
       "      <td>0.015206</td>\n",
       "      <td>0.001779</td>\n",
       "      <td>0.117017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sure</th>\n",
       "      <td>0.015206</td>\n",
       "      <td>0.001779</td>\n",
       "      <td>0.117017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ok</th>\n",
       "      <td>0.061100</td>\n",
       "      <td>0.007117</td>\n",
       "      <td>0.116488</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>said</th>\n",
       "      <td>0.016312</td>\n",
       "      <td>0.001779</td>\n",
       "      <td>0.109084</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>morning</th>\n",
       "      <td>0.016865</td>\n",
       "      <td>0.001779</td>\n",
       "      <td>0.105507</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lol</th>\n",
       "      <td>0.017694</td>\n",
       "      <td>0.001779</td>\n",
       "      <td>0.100562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>yeah</th>\n",
       "      <td>0.017694</td>\n",
       "      <td>0.001779</td>\n",
       "      <td>0.100562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>doing</th>\n",
       "      <td>0.019077</td>\n",
       "      <td>0.001779</td>\n",
       "      <td>0.093275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ask</th>\n",
       "      <td>0.019630</td>\n",
       "      <td>0.001779</td>\n",
       "      <td>0.090647</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>way</th>\n",
       "      <td>0.019630</td>\n",
       "      <td>0.001779</td>\n",
       "      <td>0.090647</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>come</th>\n",
       "      <td>0.048936</td>\n",
       "      <td>0.003559</td>\n",
       "      <td>0.072723</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>later</th>\n",
       "      <td>0.030688</td>\n",
       "      <td>0.001779</td>\n",
       "      <td>0.057981</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>da</th>\n",
       "      <td>0.032900</td>\n",
       "      <td>0.001779</td>\n",
       "      <td>0.054084</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lor</th>\n",
       "      <td>0.032900</td>\n",
       "      <td>0.001779</td>\n",
       "      <td>0.054084</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lt</th>\n",
       "      <td>0.064142</td>\n",
       "      <td>0.001779</td>\n",
       "      <td>0.027741</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gt</th>\n",
       "      <td>0.064971</td>\n",
       "      <td>0.001779</td>\n",
       "      <td>0.027387</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7204 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 ham      spam  spam_ratio\n",
       "token                                     \n",
       "claim       0.000276  0.158363  572.798932\n",
       "prize       0.000276  0.135231  489.131673\n",
       "150p        0.000276  0.087189  315.361210\n",
       "tone        0.000276  0.085409  308.925267\n",
       "guaranteed  0.000276  0.076512  276.745552\n",
       "18          0.000276  0.069395  251.001779\n",
       "cs          0.000276  0.065836  238.129893\n",
       "www         0.000553  0.129893  234.911922\n",
       "1000        0.000276  0.056940  205.950178\n",
       "awarded     0.000276  0.053381  193.078292\n",
       "150ppm      0.000276  0.051601  186.642349\n",
       "uk          0.000553  0.099644  180.206406\n",
       "500         0.000276  0.048043  173.770463\n",
       "ringtone    0.000276  0.044484  160.898577\n",
       "mob         0.000276  0.042705  154.462633\n",
       "000         0.000276  0.042705  154.462633\n",
       "collection  0.000276  0.039146  141.590747\n",
       "2000        0.000276  0.037367  135.154804\n",
       "valid       0.000276  0.037367  135.154804\n",
       "10p         0.000276  0.037367  135.154804\n",
       "800         0.000276  0.037367  135.154804\n",
       "8007        0.000276  0.035587  128.718861\n",
       "16          0.000553  0.067616  122.282918\n",
       "weekly      0.000276  0.033808  122.282918\n",
       "tones       0.000276  0.032028  115.846975\n",
       "land        0.000276  0.032028  115.846975\n",
       "http        0.000276  0.032028  115.846975\n",
       "5000        0.000276  0.030249  109.411032\n",
       "national    0.000276  0.030249  109.411032\n",
       "sae         0.000276  0.030249  109.411032\n",
       "...              ...       ...         ...\n",
       "didn        0.011335  0.001779    0.156974\n",
       "coming      0.011612  0.001779    0.153237\n",
       "wat         0.023500  0.003559    0.151434\n",
       "fine        0.011888  0.001779    0.149673\n",
       "gonna       0.012165  0.001779    0.146271\n",
       "late        0.012165  0.001779    0.146271\n",
       "oh          0.024882  0.003559    0.143021\n",
       "ya          0.012441  0.001779    0.143021\n",
       "went        0.012718  0.001779    0.139912\n",
       "ll          0.052530  0.007117    0.135494\n",
       "feel        0.013824  0.001779    0.128719\n",
       "told        0.013824  0.001779    0.128719\n",
       "gud         0.014100  0.001779    0.126195\n",
       "cos         0.014929  0.001779    0.119184\n",
       "amp         0.015206  0.001779    0.117017\n",
       "sure        0.015206  0.001779    0.117017\n",
       "ok          0.061100  0.007117    0.116488\n",
       "said        0.016312  0.001779    0.109084\n",
       "morning     0.016865  0.001779    0.105507\n",
       "lol         0.017694  0.001779    0.100562\n",
       "yeah        0.017694  0.001779    0.100562\n",
       "doing       0.019077  0.001779    0.093275\n",
       "ask         0.019630  0.001779    0.090647\n",
       "way         0.019630  0.001779    0.090647\n",
       "come        0.048936  0.003559    0.072723\n",
       "later       0.030688  0.001779    0.057981\n",
       "da          0.032900  0.001779    0.054084\n",
       "lor         0.032900  0.001779    0.054084\n",
       "lt          0.064142  0.001779    0.027741\n",
       "gt          0.064971  0.001779    0.027387\n",
       "\n",
       "[7204 rows x 3 columns]"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# examine the DataFrame sorted by spam_ratio\n",
    "# note: use sort() instead of sort_values() for pandas 0.16.2 and earlier\n",
    "tokens.sort_values('spam_ratio', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove English stop words\n",
    "vect = CountVectorizer(stop_words='english')        ########## run all the codes again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ignore terms that appear in more than 50% of the documents\n",
    "vect = CountVectorizer(max_df=0.5                                      #by running this shape is still 7456 hence no trmrs appears\n",
    "                                                                 #in more than 50% documnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "#only keep terms that appear in at least 2 documents\n",
    "vect = CountVectorizer(min_df=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=pd.read_csv('https://raw.githubusercontent.com/justmarkham/pycon-2016-tutorial/master/data/yelp.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    My wife took me here on my birthday for breakf...\n",
       "1    I have no idea why some people give bad review...\n",
       "Name: text, dtype: object"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.text[0:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "yelp=data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['business_id', 'date', 'review_id', 'stars', 'text', 'type', 'user_id',\n",
       "       'cool', 'useful', 'funny'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yelp.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4    3526\n",
       "5    3337\n",
       "3    1461\n",
       "2     927\n",
       "1     749\n",
       "Name: stars, dtype: int64"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yelp.stars.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1     749\n",
       "2     927\n",
       "3    1461\n",
       "4    3526\n",
       "5    3337\n",
       "Name: stars, dtype: int64"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# examine the class distribution\n",
    "yelp.stars.value_counts().sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "yelp_best_wrost=yelp.loc[((yelp.stars==5)|(yelp.stars==1)),:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [],
   "source": [
    "yelp_best_wrost.shape\n",
    "X=yelp_best_wrost.text\n",
    "y=yelp_best_wrost.stars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,X_test,y_train,y_test=train_test_split(X,y,random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3064,)\n",
      "(1022,)\n",
      "(3064,)\n",
      "(1022,)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# examine the object shapes\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import and instantiate CountVectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "vect = CountVectorizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "        ngram_range=(1, 1), preprocessor=None, stop_words=None,\n",
       "        strip_accents=None, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "        tokenizer=None, vocabulary=None)"
      ]
     },
     "execution_count": 220,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vect.fit(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3064, 16825)"
      ]
     },
     "execution_count": 221,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_dtm=vect.transform(X_train)\n",
    "X_train_dtm.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1022, 16825)"
      ]
     },
     "execution_count": 222,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test_dtm=vect.transform(X_test)\n",
    "X_test_dtm.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import and instantiate MultinomialNB\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "nb = MultinomialNB()\n",
    "\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "log=LogisticRegression()\n",
    "\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rf=RandomForestClassifier()\n",
    "\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "svc=SVC()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score of MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True) 0.9187866927592955\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sandY\\AppData\\Local\\conda\\conda\\envs\\tensorflow\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score of LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='warn',\n",
      "          n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
      "          tol=0.0001, verbose=0, warm_start=False) 0.9256360078277887\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sandY\\AppData\\Local\\conda\\conda\\envs\\tensorflow\\lib\\site-packages\\sklearn\\ensemble\\forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score of RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=None,\n",
      "            oob_score=False, random_state=None, verbose=0,\n",
      "            warm_start=False) 0.8816046966731899\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sandY\\AppData\\Local\\conda\\conda\\envs\\tensorflow\\lib\\site-packages\\sklearn\\svm\\base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score of SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
      "  decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "  kernel='rbf', max_iter=-1, probability=False, random_state=None,\n",
      "  shrinking=True, tol=0.001, verbose=False) 0.8199608610567515\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for i in [nb,log,rf,svc]:\n",
    "    i.fit(X_train_dtm,y_train)\n",
    "    print(\"score of {}\".format(i), i.score(X_test_dtm,y_test) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4    884\n",
       "5    832\n",
       "3    365\n",
       "2    234\n",
       "1    185\n",
       "Name: stars, dtype: int64"
      ]
     },
     "execution_count": 213,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[26.,  4.,  1., ...,  0.,  0.,  0.],\n",
       "       [39.,  5.,  0., ...,  1.,  1.,  1.]])"
      ]
     },
     "execution_count": 225,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nb.feature_count_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5    0.819961\n",
       "1    0.180039\n",
       "Name: stars, dtype: float64"
      ]
     },
     "execution_count": 232,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8199608610567515"
      ]
     },
     "execution_count": 230,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "838 / float(838 + 184)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2175    This has to be the worst restaurant in terms o...\n",
       "1781    If you like the stuck up Scottsdale vibe this ...\n",
       "2674    I'm sorry to be what seems to be the lone one ...\n",
       "9984    Went last night to Whore Foods to get basics t...\n",
       "3392    I found Lisa G's while driving through phoenix...\n",
       "8283    Don't know where I should start. Grand opening...\n",
       "2765    Went last week, and ordered a dozen variety. I...\n",
       "2839    Never Again,\\nI brought my Mountain Bike in (w...\n",
       "321     My wife and I live around the corner, hadn't e...\n",
       "1919                                         D-scust-ing.\n",
       "Name: text, dtype: object"
      ]
     },
     "execution_count": 235,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# first 10 false positives (1-star reviews incorrectly classified as 5-star reviews)\n",
    "X_test[y_test < nb.predict(X_test_dtm)].head(10)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"If you like the stuck up Scottsdale vibe this is a good place for you. The food isn't impressive. Nice outdoor seating.\""
      ]
     },
     "execution_count": 236,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test[1781] # model is searching for word nice good impresive thts y rated high "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'D-scust-ing.'"
      ]
     },
     "execution_count": 237,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test[1919] ## model has no data to work with"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7148    I now consider myself an Arizonian. If you dri...\n",
       "4963    This is by far my favourite department store, ...\n",
       "6318    Since I have ranted recently on poor customer ...\n",
       "380     This is a must try for any Mani Pedi fan. I us...\n",
       "5565    I`ve had work done by this shop a few times th...\n",
       "3448    I was there last week with my sisters and whil...\n",
       "6050    I went to sears today to check on a layaway th...\n",
       "2504    I've passed by prestige nails in walmart 100s ...\n",
       "2475    This place is so great! I am a nanny and had t...\n",
       "241     I was sad to come back to lai lai's and they n...\n",
       "Name: text, dtype: object"
      ]
     },
     "execution_count": 241,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# first 10 false negatives (5-star reviews incorrectly classified as 1-star reviews)\n",
    "X_test[y_test > nb.predict(X_test_dtm)].head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'This is by far my favourite department store, hands down. I have had nothing but perfect experiences in this store, without exception, no matter what department I\\'m in. The shoe SA\\'s will bend over backwards to help you find a specific shoe, and the staff will even go so far as to send out hand-written thank you cards to your home address after you make a purchase - big or small. Tim & Anthony in the shoe salon are fabulous beyond words! \\n\\nI am not completely sure that I understand why people complain about the amount of merchandise on the floor or the lack of crowds in this store. Frankly, I would rather not be bombarded with merchandise and other people. One of the things I love the most about Barney\\'s is not only the prompt attention of SA\\'s, but the fact that they aren\\'t rushing around trying to help 35 people at once. The SA\\'s at Barney\\'s are incredibly friendly and will stop to have an actual conversation, regardless or whether you are purchasing something or not. I have also never experienced a \"high pressure\" sale situation here.\\n\\nAll in all, Barneys is pricey, and there is no getting around it. But, um, so is Neiman\\'s and that place is a crock. Anywhere that ONLY accepts American Express or their charge card and then treats you like scum if you aren\\'t carrying neither is no place that I want to spend my hard earned dollars. Yay Barneys!'"
      ]
     },
     "execution_count": 242,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test[4963] \n",
    "# false negative: model is reacting to the words \"complain\", \"crowds\", \"rushing\", \"pricey\", \"scum\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16825"
      ]
     },
     "execution_count": 243,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# store the vocabulary of X_train\n",
    "X_train_tokens = vect.get_feature_names()\n",
    "len(X_train_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [],
   "source": [
    "# store the number of times each token appears across each class\n",
    "one_star_token_count = nb.feature_count_[0, :]\n",
    "five_star_token_count = nb.feature_count_[1, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['00',\n",
       " '000',\n",
       " '00a',\n",
       " '00am',\n",
       " '00pm',\n",
       " '01',\n",
       " '02',\n",
       " '03',\n",
       " '03342',\n",
       " '04',\n",
       " '05',\n",
       " '06',\n",
       " '07',\n",
       " '09',\n",
       " '0buxoc0crqjpvkezo3bqog',\n",
       " '0l',\n",
       " '10',\n",
       " '100',\n",
       " '1000',\n",
       " '1000x',\n",
       " '1001',\n",
       " '100th',\n",
       " '101',\n",
       " '102',\n",
       " '105',\n",
       " '1070',\n",
       " '108',\n",
       " '10am',\n",
       " '10ish',\n",
       " '10min',\n",
       " '10mins',\n",
       " '10minutes',\n",
       " '10pm',\n",
       " '10th',\n",
       " '10x',\n",
       " '11',\n",
       " '110',\n",
       " '1100',\n",
       " '111',\n",
       " '111th',\n",
       " '112',\n",
       " '115th',\n",
       " '118',\n",
       " '11a',\n",
       " '11am',\n",
       " '11p',\n",
       " '11pm',\n",
       " '12',\n",
       " '120',\n",
       " '128i',\n",
       " '129',\n",
       " '12am',\n",
       " '12oz',\n",
       " '12pm',\n",
       " '12th',\n",
       " '13',\n",
       " '14',\n",
       " '140',\n",
       " '147',\n",
       " '14lbs',\n",
       " '15',\n",
       " '150',\n",
       " '1500',\n",
       " '150mm',\n",
       " '15am',\n",
       " '15mins',\n",
       " '15pm',\n",
       " '15th',\n",
       " '16',\n",
       " '160',\n",
       " '165',\n",
       " '169',\n",
       " '16th',\n",
       " '17',\n",
       " '17p',\n",
       " '18',\n",
       " '180',\n",
       " '18th',\n",
       " '19',\n",
       " '1900',\n",
       " '1913',\n",
       " '1928',\n",
       " '1929',\n",
       " '1930s',\n",
       " '1940',\n",
       " '1952',\n",
       " '1955',\n",
       " '1956',\n",
       " '1960',\n",
       " '1961',\n",
       " '1969',\n",
       " '1970',\n",
       " '1980',\n",
       " '1980s',\n",
       " '1987',\n",
       " '1990s',\n",
       " '1992',\n",
       " '1995',\n",
       " '1996',\n",
       " '1998',\n",
       " '1999',\n",
       " '19th',\n",
       " '1cent',\n",
       " '1k',\n",
       " '1p',\n",
       " '1pm',\n",
       " '1st',\n",
       " '20',\n",
       " '200',\n",
       " '2002',\n",
       " '2003',\n",
       " '2004',\n",
       " '2005',\n",
       " '2006',\n",
       " '2007',\n",
       " '2008',\n",
       " '2009',\n",
       " '200lbs',\n",
       " '2010',\n",
       " '2011',\n",
       " '2012',\n",
       " '202',\n",
       " '20mbs',\n",
       " '20miles',\n",
       " '20min',\n",
       " '20pm',\n",
       " '20s',\n",
       " '20th',\n",
       " '20x',\n",
       " '21',\n",
       " '22',\n",
       " '220',\n",
       " '2240',\n",
       " '22oz',\n",
       " '23',\n",
       " '24',\n",
       " '24hrs',\n",
       " '24st',\n",
       " '24th',\n",
       " '25',\n",
       " '250',\n",
       " '25b',\n",
       " '25min',\n",
       " '25th',\n",
       " '26',\n",
       " '260',\n",
       " '2600',\n",
       " '2608',\n",
       " '2669',\n",
       " '26th',\n",
       " '27',\n",
       " '272',\n",
       " '28',\n",
       " '29',\n",
       " '29th',\n",
       " '2am',\n",
       " '2mbps',\n",
       " '2nd',\n",
       " '2pm',\n",
       " '2rd',\n",
       " '2wice',\n",
       " '2x',\n",
       " '30',\n",
       " '300',\n",
       " '3000',\n",
       " '30am',\n",
       " '30p',\n",
       " '30pm',\n",
       " '30th',\n",
       " '31',\n",
       " '311',\n",
       " '312',\n",
       " '32',\n",
       " '33',\n",
       " '33rd',\n",
       " '34',\n",
       " '34th',\n",
       " '35',\n",
       " '350ib',\n",
       " '35c',\n",
       " '35th',\n",
       " '36',\n",
       " '37',\n",
       " '370',\n",
       " '38',\n",
       " '38th',\n",
       " '39',\n",
       " '3am',\n",
       " '3d',\n",
       " '3g',\n",
       " '3k',\n",
       " '3lbs',\n",
       " '3n9u549zse8up',\n",
       " '3p',\n",
       " '3pm',\n",
       " '3rd',\n",
       " '3x',\n",
       " '40',\n",
       " '400',\n",
       " '4000',\n",
       " '40lm',\n",
       " '40min',\n",
       " '40th',\n",
       " '41',\n",
       " '411',\n",
       " '4113416766',\n",
       " '42',\n",
       " '420',\n",
       " '43',\n",
       " '44',\n",
       " '4458',\n",
       " '44th',\n",
       " '45',\n",
       " '453990',\n",
       " '45min',\n",
       " '45pm',\n",
       " '46',\n",
       " '475',\n",
       " '48',\n",
       " '480',\n",
       " '48th',\n",
       " '49',\n",
       " '490',\n",
       " '4b',\n",
       " '4hr',\n",
       " '4pm',\n",
       " '4th',\n",
       " '50',\n",
       " '500',\n",
       " '50cents',\n",
       " '50lm',\n",
       " '50s',\n",
       " '51',\n",
       " '51pm',\n",
       " '52',\n",
       " '5231',\n",
       " '53',\n",
       " '53pm',\n",
       " '54',\n",
       " '55',\n",
       " '56',\n",
       " '57',\n",
       " '59',\n",
       " '59th',\n",
       " '5k',\n",
       " '5min',\n",
       " '5p',\n",
       " '5pm',\n",
       " '5stars',\n",
       " '5th',\n",
       " '60',\n",
       " '600',\n",
       " '602',\n",
       " '61',\n",
       " '61st',\n",
       " '62010',\n",
       " '623',\n",
       " '63',\n",
       " '64',\n",
       " '64th',\n",
       " '65',\n",
       " '66',\n",
       " '67',\n",
       " '68',\n",
       " '680',\n",
       " '69',\n",
       " '6am',\n",
       " '6p',\n",
       " '6pm',\n",
       " '6th',\n",
       " '70',\n",
       " '700',\n",
       " '70s',\n",
       " '70th',\n",
       " '71',\n",
       " '71st',\n",
       " '75',\n",
       " '750',\n",
       " '755891987',\n",
       " '76',\n",
       " '79',\n",
       " '7am',\n",
       " '7pm',\n",
       " '7th',\n",
       " '80',\n",
       " '800',\n",
       " '8000hp',\n",
       " '80s',\n",
       " '81',\n",
       " '83',\n",
       " '832',\n",
       " '83rd',\n",
       " '85',\n",
       " '85154658',\n",
       " '86',\n",
       " '88',\n",
       " '89',\n",
       " '8am',\n",
       " '8pm',\n",
       " '8th',\n",
       " '8v',\n",
       " '8yo',\n",
       " '90',\n",
       " '90s',\n",
       " '91',\n",
       " '911',\n",
       " '945am',\n",
       " '95',\n",
       " '96',\n",
       " '977',\n",
       " '98',\n",
       " '99',\n",
       " '9999',\n",
       " '99cent',\n",
       " '9oz',\n",
       " '9p',\n",
       " '9pm',\n",
       " '9year',\n",
       " '9yo',\n",
       " '______',\n",
       " '_______________',\n",
       " '_c',\n",
       " '_gyib8ea4hdfylss17zc_g',\n",
       " 'a1',\n",
       " 'aa',\n",
       " 'aaa',\n",
       " 'aaaamazing',\n",
       " 'aaammmazzing',\n",
       " 'aaron',\n",
       " 'ab',\n",
       " 'abandoned',\n",
       " 'abandoning',\n",
       " 'abba',\n",
       " 'abbreviate',\n",
       " 'abbreviated',\n",
       " 'abby',\n",
       " 'abc',\n",
       " 'abdomen',\n",
       " 'abilities',\n",
       " 'ability',\n",
       " 'able',\n",
       " 'abodoba',\n",
       " 'abound',\n",
       " 'about',\n",
       " 'above',\n",
       " 'abrasion',\n",
       " 'abroad',\n",
       " 'abrupt',\n",
       " 'absent',\n",
       " 'absinthe',\n",
       " 'absoloutely',\n",
       " 'absolut',\n",
       " 'absolute',\n",
       " 'absolutely',\n",
       " 'absolutley',\n",
       " 'absolutly',\n",
       " 'abstained',\n",
       " 'absurd',\n",
       " 'abuelo',\n",
       " 'abundance',\n",
       " 'abundant',\n",
       " 'abuse',\n",
       " 'abused',\n",
       " 'abusive',\n",
       " 'ac',\n",
       " 'academy',\n",
       " 'acapulco',\n",
       " 'accent',\n",
       " 'accented',\n",
       " 'accents',\n",
       " 'accept',\n",
       " 'acceptable',\n",
       " 'accepted',\n",
       " 'access',\n",
       " 'accessed',\n",
       " 'accessible',\n",
       " 'accessories',\n",
       " 'accessorize',\n",
       " 'accessory',\n",
       " 'accident',\n",
       " 'accidental',\n",
       " 'accidentally',\n",
       " 'accolades',\n",
       " 'accommodate',\n",
       " 'accommodated',\n",
       " 'accommodates',\n",
       " 'accommodating',\n",
       " 'accommodations',\n",
       " 'accomodate',\n",
       " 'accomodating',\n",
       " 'accompanied',\n",
       " 'accompanies',\n",
       " 'accompaniment',\n",
       " 'accompany',\n",
       " 'accompanying',\n",
       " 'accomplish',\n",
       " 'accomplished',\n",
       " 'accomplishment',\n",
       " 'according',\n",
       " 'accordingly',\n",
       " 'account',\n",
       " 'accounts',\n",
       " 'accoutrement',\n",
       " 'accredited',\n",
       " 'accross',\n",
       " 'accurate',\n",
       " 'accurately',\n",
       " 'accusation',\n",
       " 'accustom',\n",
       " 'accustomed',\n",
       " 'accutemp',\n",
       " 'ace',\n",
       " 'ache',\n",
       " 'aches',\n",
       " 'achieve',\n",
       " 'achievement',\n",
       " 'acid',\n",
       " 'acidic',\n",
       " 'acknowledge',\n",
       " 'acknowledged',\n",
       " 'acknowledgement',\n",
       " 'acknowledging',\n",
       " 'ackward',\n",
       " 'acne',\n",
       " 'acoustic',\n",
       " 'acoustics',\n",
       " 'acquaintance',\n",
       " 'acres',\n",
       " 'acrid',\n",
       " 'acrimonious',\n",
       " 'across',\n",
       " 'acrylics',\n",
       " 'act',\n",
       " 'acted',\n",
       " 'acting',\n",
       " 'action',\n",
       " 'actions',\n",
       " 'activation',\n",
       " 'active',\n",
       " 'actively',\n",
       " 'activism',\n",
       " 'activities',\n",
       " 'activity',\n",
       " 'actor',\n",
       " 'actors',\n",
       " 'acts',\n",
       " 'actual',\n",
       " 'actually',\n",
       " 'actualy',\n",
       " 'actully',\n",
       " 'acute',\n",
       " 'acy',\n",
       " 'ad',\n",
       " 'adage',\n",
       " 'adam',\n",
       " 'adamant',\n",
       " 'adams',\n",
       " 'adapter',\n",
       " 'add',\n",
       " 'added',\n",
       " 'addendum',\n",
       " 'addict',\n",
       " 'addicted',\n",
       " 'addicting',\n",
       " 'addictingly',\n",
       " 'addiction',\n",
       " 'addictionovercome',\n",
       " 'addictive',\n",
       " 'addicts',\n",
       " 'adding',\n",
       " 'addition',\n",
       " 'additional',\n",
       " 'additionally',\n",
       " 'additions',\n",
       " 'address',\n",
       " 'addressed',\n",
       " 'addressing',\n",
       " 'adds',\n",
       " 'ade',\n",
       " 'adelman',\n",
       " 'adequate',\n",
       " 'adequately',\n",
       " 'adios',\n",
       " 'adjacent',\n",
       " 'adjoining',\n",
       " 'adjust',\n",
       " 'adjusted',\n",
       " 'adjustment',\n",
       " 'adjustments',\n",
       " 'administrative',\n",
       " 'admire',\n",
       " 'admission',\n",
       " 'admit',\n",
       " 'admits',\n",
       " 'admitted',\n",
       " 'admittedly',\n",
       " 'admitting',\n",
       " 'admonishment',\n",
       " 'adobada',\n",
       " 'adobe',\n",
       " 'adobo',\n",
       " 'adolescence',\n",
       " 'adopt',\n",
       " 'adopted',\n",
       " 'adoption',\n",
       " 'adoptions',\n",
       " 'adorable',\n",
       " 'adore',\n",
       " 'adorning',\n",
       " 'adovada',\n",
       " 'adquate',\n",
       " 'adrienne',\n",
       " 'ads',\n",
       " 'adult',\n",
       " 'adulthood',\n",
       " 'adults',\n",
       " 'advance',\n",
       " 'advanced',\n",
       " 'advancing',\n",
       " 'advantage',\n",
       " 'advantages',\n",
       " 'adventure',\n",
       " 'adventures',\n",
       " 'adventurous',\n",
       " 'adverse',\n",
       " 'adversity',\n",
       " 'advertise',\n",
       " 'advertised',\n",
       " 'advertisement',\n",
       " 'advertising',\n",
       " 'adverts',\n",
       " 'advice',\n",
       " 'advise',\n",
       " 'advised',\n",
       " 'advising',\n",
       " 'advisor',\n",
       " 'advocate',\n",
       " 'advocated',\n",
       " 'aeg',\n",
       " 'aerators',\n",
       " 'aerobic',\n",
       " 'aerobics',\n",
       " 'aeropress',\n",
       " 'aesthetically',\n",
       " 'aesthetics',\n",
       " 'affair',\n",
       " 'affect',\n",
       " 'affected',\n",
       " 'affects',\n",
       " 'afficianados',\n",
       " 'affiliated',\n",
       " 'affiliation',\n",
       " 'affluent',\n",
       " 'afforadable',\n",
       " 'afford',\n",
       " 'affordable',\n",
       " 'aficionado',\n",
       " 'aficionados',\n",
       " 'afloat',\n",
       " 'aforementioned',\n",
       " 'afoul',\n",
       " 'afraid',\n",
       " 'africa',\n",
       " 'after',\n",
       " 'afterall',\n",
       " 'afterdark',\n",
       " 'afterglow',\n",
       " 'afternoon',\n",
       " 'afternoons',\n",
       " 'aftertaste',\n",
       " 'afterthought',\n",
       " 'afterward',\n",
       " 'afterwards',\n",
       " 'again',\n",
       " 'against',\n",
       " 'agape',\n",
       " 'agave',\n",
       " 'agaves',\n",
       " 'age',\n",
       " 'aged',\n",
       " 'agency',\n",
       " 'agent',\n",
       " 'agents',\n",
       " 'ages',\n",
       " 'aggressive',\n",
       " 'aging',\n",
       " 'agitated',\n",
       " 'ago',\n",
       " 'agonizing',\n",
       " 'agree',\n",
       " 'agreeable',\n",
       " 'agreed',\n",
       " 'agreeing',\n",
       " 'agreement',\n",
       " 'agrees',\n",
       " 'agua',\n",
       " 'aguas',\n",
       " 'agwa',\n",
       " 'ah',\n",
       " 'ahead',\n",
       " 'ahem',\n",
       " 'ahh',\n",
       " 'ahhh',\n",
       " 'ahhhh',\n",
       " 'ahhhhh',\n",
       " 'ahi',\n",
       " 'ahold',\n",
       " 'ahwatukee',\n",
       " 'aid',\n",
       " 'aiello',\n",
       " 'aiko',\n",
       " 'aim',\n",
       " 'aimed',\n",
       " 'aimlessly',\n",
       " 'aims',\n",
       " 'ain',\n",
       " 'aint',\n",
       " 'aioli',\n",
       " 'aiptasia',\n",
       " 'air',\n",
       " 'airconditioned',\n",
       " 'airfair',\n",
       " 'airfare',\n",
       " 'airline',\n",
       " 'airlines',\n",
       " 'airpark',\n",
       " 'airplane',\n",
       " 'airport',\n",
       " 'airports',\n",
       " 'airwarys',\n",
       " 'airways',\n",
       " 'airy',\n",
       " 'aisha',\n",
       " 'aisle',\n",
       " 'aisles',\n",
       " 'aj',\n",
       " 'aji',\n",
       " 'ajo',\n",
       " 'ajos',\n",
       " 'ajs',\n",
       " 'ajvar',\n",
       " 'aka',\n",
       " 'aki',\n",
       " 'aknowledging',\n",
       " 'akor',\n",
       " 'al',\n",
       " 'ala',\n",
       " 'alabama',\n",
       " 'alain',\n",
       " 'alameda',\n",
       " 'alan',\n",
       " 'alarmed',\n",
       " 'alas',\n",
       " 'alaskan',\n",
       " 'alaus',\n",
       " 'albacore',\n",
       " 'albeit',\n",
       " 'alber',\n",
       " 'album',\n",
       " 'albums',\n",
       " 'alcohol',\n",
       " 'alcoholic',\n",
       " 'aldo',\n",
       " 'ale',\n",
       " 'alert',\n",
       " 'alex',\n",
       " 'alexandra',\n",
       " 'alfalfa',\n",
       " 'alfonso',\n",
       " 'alfred',\n",
       " 'alfredo',\n",
       " 'algae',\n",
       " 'ali',\n",
       " 'alice',\n",
       " 'alicia',\n",
       " 'aliens',\n",
       " 'alike',\n",
       " 'alittle',\n",
       " 'alive',\n",
       " 'all',\n",
       " 'alla',\n",
       " 'allayed',\n",
       " 'alleged',\n",
       " 'allegiant',\n",
       " 'allen',\n",
       " 'allende',\n",
       " 'allergen',\n",
       " 'allergic',\n",
       " 'allergies',\n",
       " 'allergy',\n",
       " 'alleviated',\n",
       " 'alley',\n",
       " 'alligator',\n",
       " 'allocating',\n",
       " 'allot',\n",
       " 'alloted',\n",
       " 'allotted',\n",
       " 'allow',\n",
       " 'allowable',\n",
       " 'allowance',\n",
       " 'allowed',\n",
       " 'allowing',\n",
       " 'allows',\n",
       " 'allure',\n",
       " 'almond',\n",
       " 'almonds',\n",
       " 'almost',\n",
       " 'aloe',\n",
       " 'alofts',\n",
       " 'aloha',\n",
       " 'alone',\n",
       " 'along',\n",
       " 'alongside',\n",
       " 'alons',\n",
       " 'aloo',\n",
       " 'aloof',\n",
       " 'alot',\n",
       " 'aloud',\n",
       " 'alp',\n",
       " 'already',\n",
       " 'alright',\n",
       " 'also',\n",
       " 'alteration',\n",
       " 'alterations',\n",
       " 'altercation',\n",
       " 'altered',\n",
       " 'altering',\n",
       " 'alternately',\n",
       " 'alternative',\n",
       " 'alternatively',\n",
       " 'alternatives',\n",
       " 'although',\n",
       " 'altic',\n",
       " 'aluminum',\n",
       " 'alway',\n",
       " 'always',\n",
       " 'am',\n",
       " 'ama',\n",
       " 'amaaaaazing',\n",
       " 'amaazing',\n",
       " 'amados',\n",
       " 'amalfi',\n",
       " 'amanda',\n",
       " 'amaretti',\n",
       " 'amaretto',\n",
       " 'amarillo',\n",
       " 'amaro',\n",
       " 'amateur',\n",
       " 'amaze',\n",
       " 'amazed',\n",
       " 'amazement',\n",
       " 'amazes',\n",
       " 'amazing',\n",
       " 'amazingly',\n",
       " 'amazingness',\n",
       " 'amazon',\n",
       " 'amazzzzzzing',\n",
       " 'ambassador',\n",
       " 'amber',\n",
       " 'ambiance',\n",
       " 'ambience',\n",
       " 'ambient',\n",
       " 'ambrosia',\n",
       " 'amc',\n",
       " 'amenable',\n",
       " 'amendment',\n",
       " 'amenities',\n",
       " 'america',\n",
       " 'american',\n",
       " 'americana',\n",
       " 'americanized',\n",
       " 'americano',\n",
       " 'americanos',\n",
       " 'americans',\n",
       " 'ami',\n",
       " 'amicable',\n",
       " 'amidst',\n",
       " 'amin',\n",
       " 'amish',\n",
       " 'ammo',\n",
       " 'amomi',\n",
       " 'among',\n",
       " 'amongst',\n",
       " 'amore',\n",
       " 'amount',\n",
       " 'amounted',\n",
       " 'amounts',\n",
       " 'amp',\n",
       " 'amphitheatre',\n",
       " 'ample',\n",
       " 'ampm',\n",
       " 'amtrack',\n",
       " 'amuse',\n",
       " 'amused',\n",
       " 'amusement',\n",
       " 'amusing',\n",
       " 'amy',\n",
       " 'an',\n",
       " 'anal',\n",
       " 'analysis',\n",
       " 'ancho',\n",
       " 'anchor',\n",
       " 'anchors',\n",
       " 'anchovies',\n",
       " 'anchovy',\n",
       " 'and',\n",
       " 'andiamo',\n",
       " 'andouille',\n",
       " 'andrea',\n",
       " 'andrew',\n",
       " 'andy',\n",
       " 'anecdotes',\n",
       " 'anemic',\n",
       " 'anesthetic',\n",
       " 'anew',\n",
       " 'angel',\n",
       " 'angela',\n",
       " 'angeles',\n",
       " 'angelic',\n",
       " 'angello',\n",
       " 'angels',\n",
       " 'anger',\n",
       " 'anglaise',\n",
       " 'angle',\n",
       " 'angler',\n",
       " 'angles',\n",
       " 'angry',\n",
       " 'angst',\n",
       " 'anibal',\n",
       " 'animal',\n",
       " 'animals',\n",
       " 'animated',\n",
       " 'animatronics',\n",
       " 'anise',\n",
       " 'aniston',\n",
       " 'ankle',\n",
       " 'ankles',\n",
       " 'ann',\n",
       " 'anne',\n",
       " 'annie',\n",
       " 'annihilator',\n",
       " 'anniversary',\n",
       " 'announced',\n",
       " 'annoy',\n",
       " 'annoyance',\n",
       " 'annoyed',\n",
       " 'annoying',\n",
       " 'annual',\n",
       " 'anomaly',\n",
       " 'anonymous',\n",
       " 'another',\n",
       " 'ans',\n",
       " 'ansel',\n",
       " 'answer',\n",
       " 'answered',\n",
       " 'answering',\n",
       " 'answers',\n",
       " 'ant',\n",
       " 'anthem',\n",
       " 'anthony',\n",
       " 'anti',\n",
       " 'anticipate',\n",
       " 'anticipated',\n",
       " 'anticipating',\n",
       " 'anticipation',\n",
       " 'antipasti',\n",
       " 'antipasto',\n",
       " 'antique',\n",
       " 'antiques',\n",
       " 'antiquing',\n",
       " 'antiseptic',\n",
       " 'antithesis',\n",
       " 'antler',\n",
       " 'antonio',\n",
       " 'antono',\n",
       " 'ants',\n",
       " 'anxiety',\n",
       " 'anxious',\n",
       " 'anxiously',\n",
       " 'any',\n",
       " 'anybody',\n",
       " 'anyday',\n",
       " 'anyhoo',\n",
       " 'anyhow',\n",
       " 'anymore',\n",
       " 'anyone',\n",
       " 'anyplace',\n",
       " 'anything',\n",
       " 'anythings',\n",
       " 'anytime',\n",
       " 'anyway',\n",
       " 'anyways',\n",
       " 'anywhere',\n",
       " 'anywho',\n",
       " 'ao',\n",
       " 'ap',\n",
       " 'apache',\n",
       " 'apart',\n",
       " 'apartment',\n",
       " 'apartments',\n",
       " 'ape',\n",
       " 'apiece',\n",
       " 'apologetic',\n",
       " 'apologetically',\n",
       " 'apologists',\n",
       " 'apologize',\n",
       " 'apologized',\n",
       " 'apologizes',\n",
       " 'apologizing',\n",
       " 'apology',\n",
       " 'apostles',\n",
       " 'apothecary',\n",
       " 'apothic',\n",
       " 'app',\n",
       " 'appalachians',\n",
       " 'appaled',\n",
       " 'appalled',\n",
       " 'appalling',\n",
       " 'apparantly',\n",
       " 'apparel',\n",
       " 'apparent',\n",
       " 'apparently',\n",
       " 'appauling',\n",
       " 'appeal',\n",
       " 'appealed',\n",
       " 'appealing',\n",
       " 'appeals',\n",
       " 'appear',\n",
       " 'appearance',\n",
       " 'appearances',\n",
       " 'appeared',\n",
       " 'appears',\n",
       " 'appeasing',\n",
       " 'appertizer',\n",
       " 'appetit',\n",
       " 'appetite',\n",
       " 'appetito',\n",
       " 'appetizaer',\n",
       " 'appetizer',\n",
       " 'appetizers',\n",
       " 'appetizing',\n",
       " 'applaud',\n",
       " 'apple',\n",
       " 'applebee',\n",
       " 'applebees',\n",
       " 'apples',\n",
       " 'appletini',\n",
       " 'appletinis',\n",
       " 'appliances',\n",
       " 'applied',\n",
       " 'applies',\n",
       " 'apply',\n",
       " 'applying',\n",
       " 'appoinmtnt',\n",
       " 'appointed',\n",
       " 'appointment',\n",
       " 'appointments',\n",
       " 'appologized',\n",
       " 'appraisal',\n",
       " 'appraisals',\n",
       " 'appraiser',\n",
       " 'appreciate',\n",
       " 'appreciated',\n",
       " 'appreciates',\n",
       " 'appreciation',\n",
       " 'appreciative',\n",
       " 'apprehensive',\n",
       " 'appreicate',\n",
       " 'approach',\n",
       " 'approachable',\n",
       " 'approached',\n",
       " 'approaches',\n",
       " 'approaching',\n",
       " 'appropriate',\n",
       " 'appropriately',\n",
       " 'approx',\n",
       " 'approximate',\n",
       " 'approximately',\n",
       " 'apps',\n",
       " 'appt',\n",
       " 'appys',\n",
       " 'apricot',\n",
       " 'april',\n",
       " 'apron',\n",
       " 'apt',\n",
       " 'aqua',\n",
       " 'aquarium',\n",
       " 'aquiring',\n",
       " 'ar',\n",
       " 'arabic',\n",
       " 'arai',\n",
       " 'arbol',\n",
       " 'arboreal',\n",
       " 'arborio',\n",
       " 'arcade',\n",
       " 'arcadia',\n",
       " 'arcane',\n",
       " 'arches',\n",
       " 'architect',\n",
       " 'architecture',\n",
       " ...]"
      ]
     },
     "execution_count": 245,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a DataFrame of tokens with their separate one-star and five-star counts\n",
    "tokens = pd.DataFrame({'token':X_train_tokens, 'one_star':one_star_token_count, 'five_star':five_star_token_count}).set_index('token')\n",
    "# add 1 to one-star and five-star counts to avoid dividing by 0\n",
    "tokens['one_star'] = tokens.one_star + 1\n",
    "tokens['five_star'] = tokens.five_star + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 565., 2499.])"
      ]
     },
     "execution_count": 248,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nb.class_count_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert the one-star and five-star counts into frequencies\n",
    "tokens['one_star'] = tokens.one_star / nb.class_count_[0]\n",
    "tokens['five_star'] = tokens.five_star / nb.class_count_[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens[\"five_star_ratio\"]=tokens.five_star/tokens.one_star"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>one_star</th>\n",
       "      <th>five_star</th>\n",
       "      <th>five_star_ratio</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>token</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>fantastic</th>\n",
       "      <td>0.003540</td>\n",
       "      <td>0.077231</td>\n",
       "      <td>21.817727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>perfect</th>\n",
       "      <td>0.005310</td>\n",
       "      <td>0.098039</td>\n",
       "      <td>18.464052</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>yum</th>\n",
       "      <td>0.001770</td>\n",
       "      <td>0.024810</td>\n",
       "      <td>14.017607</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>favorite</th>\n",
       "      <td>0.012389</td>\n",
       "      <td>0.138055</td>\n",
       "      <td>11.143029</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>outstanding</th>\n",
       "      <td>0.001770</td>\n",
       "      <td>0.019608</td>\n",
       "      <td>11.078431</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>brunch</th>\n",
       "      <td>0.001770</td>\n",
       "      <td>0.016807</td>\n",
       "      <td>9.495798</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gem</th>\n",
       "      <td>0.001770</td>\n",
       "      <td>0.016006</td>\n",
       "      <td>9.043617</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mozzarella</th>\n",
       "      <td>0.001770</td>\n",
       "      <td>0.015606</td>\n",
       "      <td>8.817527</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pasty</th>\n",
       "      <td>0.001770</td>\n",
       "      <td>0.015606</td>\n",
       "      <td>8.817527</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>amazing</th>\n",
       "      <td>0.021239</td>\n",
       "      <td>0.185274</td>\n",
       "      <td>8.723323</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             one_star  five_star  five_star_ratio\n",
       "token                                            \n",
       "fantastic    0.003540   0.077231        21.817727\n",
       "perfect      0.005310   0.098039        18.464052\n",
       "yum          0.001770   0.024810        14.017607\n",
       "favorite     0.012389   0.138055        11.143029\n",
       "outstanding  0.001770   0.019608        11.078431\n",
       "brunch       0.001770   0.016807         9.495798\n",
       "gem          0.001770   0.016006         9.043617\n",
       "mozzarella   0.001770   0.015606         8.817527\n",
       "pasty        0.001770   0.015606         8.817527\n",
       "amazing      0.021239   0.185274         8.723323"
      ]
     },
     "execution_count": 256,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens.sort_values(\"five_star_ratio\",ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [],
   "source": [
    "##########################\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define X and y using the original DataFrame\n",
    "X = yelp.text\n",
    "y = yelp.stars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1     749\n",
       "2     927\n",
       "3    1461\n",
       "4    3526\n",
       "5    3337\n",
       "Name: stars, dtype: int64"
      ]
     },
     "execution_count": 261,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.value_counts().sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# split X and y into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create document-term matrices using CountVectorizer\n",
    "X_train_dtm = vect.fit_transform(X_train)\n",
    "X_test_dtm = vect.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit a Multinomial Naive Bayes model\n",
    "nb.fit(X_train_dtm, y_train)\n",
    "\n",
    "\n",
    "# make class predictions\n",
    "y_pred_class = nb.predict(X_test_dtm)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4712"
      ]
     },
     "execution_count": 265,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# calculate the accuary\n",
    "metrics.accuracy_score(y_test, y_pred_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4    0.3536\n",
       "Name: stars, dtype: float64"
      ]
     },
     "execution_count": 266,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# calculate the null accuracy\n",
    "y_test.value_counts().head(1) / y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4    884\n",
       "5    832\n",
       "3    365\n",
       "2    234\n",
       "1    185\n",
       "Name: stars, dtype: int64"
      ]
     },
     "execution_count": 267,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2500,)"
      ]
     },
     "execution_count": 269,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3536"
      ]
     },
     "execution_count": 270,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "884/2500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 55,  14,  24,  65,  27],\n",
       "       [ 28,  16,  41, 122,  27],\n",
       "       [  5,   7,  35, 281,  37],\n",
       "       [  7,   0,  16, 629, 232],\n",
       "       [  6,   4,   6, 373, 443]], dtype=int64)"
      ]
     },
     "execution_count": 271,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# print the confusion matrix\n",
    "metrics.confusion_matrix(y_test, y_pred_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.54      0.30      0.38       185\n",
      "           2       0.39      0.07      0.12       234\n",
      "           3       0.29      0.10      0.14       365\n",
      "           4       0.43      0.71      0.53       884\n",
      "           5       0.58      0.53      0.55       832\n",
      "\n",
      "   micro avg       0.47      0.47      0.47      2500\n",
      "   macro avg       0.45      0.34      0.35      2500\n",
      "weighted avg       0.46      0.47      0.43      2500\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# print the classification report\n",
    "print(metrics.classification_report(y_test, y_pred_class))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5445544554455446"
      ]
     },
     "execution_count": 273,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#**Precision** answers the question: \"When a given class is predicted, how often \n",
    "    #are those predictions correct?\" To calculate the precision for class 1, for example, you divide 55 by the sum of the first column of the confusion matrix.\n",
    "\n",
    "  #  precision for class 1\n",
    "55/(28+5+7+6+55)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2972972972972973"
      ]
     },
     "execution_count": 275,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# **Recall** answers the question: \"When a given class is the true class, how often is that class predicted?\" \n",
    "55/(55+14+24+65+27)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "185"
      ]
     },
     "execution_count": 276,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#SUPPORT \"How many observations exist for which a given class is the true class?\"\n",
    "55+14+24+65+27"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
